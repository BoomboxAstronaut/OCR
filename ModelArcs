
_________________________
Classifier
_________________________
Heavy Model		93.2% Accuracy	4.9M parameters	0.00045 LR

x = layers.Rescaling(1.0/255)(inlay)
x = layers.Conv2D(32, 7, padding='same', activation='relu')(x)
x = layers.Conv2D(32, 7, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Conv2D(64, 5, padding='same', activation='relu')(x)
x = layers.Conv2D(64, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Flatten()(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dropout(0.32)(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)


Med Model		91.3% Accuracy	1.6M parameters	0.0005 LR

x = layers.Rescaling(1.0/255)(inlay)
x = layers.Conv2D(16, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Conv2D(32, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Conv2D(64, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Conv2D(128, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Flatten()(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dropout(0.32)(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)


Light Model		90.3% Accuracy	841k parameters	0.001 LR

x = layers.Rescaling(1.0/255)(inlay)
x = layers.Conv2D(8, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Conv2D(16, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Flatten()(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dropout(0.32)(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)


inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 3, padding='same', activation="relu")(x)
for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.1)(x)

    res = layers.Conv2D(fsize, 1, strides=2, padding="same")(res)
    res = layers.BatchNormalization()(res)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)

x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.45)(x)
outp = layers.Dense(55, activation='softmax')(x)
	
	
	
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 3, padding='same', activation="relu")(x)

for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.1)(x)

    res = layers.Conv2D(fsize, 1, strides=2, padding="same")(res)
    res = layers.BatchNormalization()(res)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)

    res = x
    x = layers.Conv2D(fsize, 1, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize, 1, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)


x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.45)(x)
outp = layers.Dense(55, activation='softmax')(x)



inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same', activation="relu")(x)
for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.1)(x)

    res = layers.Conv2D(fsize, 1, strides=2, padding="same")(res)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)

x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.45)(x)
outp = layers.Dense(55, activation='softmax')(x)



inp = keras.Input(shape=(64, 64, 1))
x = layers.Conv2D(32, 7, padding='same')(inp)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(64, 5, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.MaxPooling2D(2, 2)(x)
for fsize in [64, 128, 256]:
    res = x
    sstep = 2
    if fsize == 64:
        sstep = 1
    x = layers.Conv2D(fsize, 1, strides=sstep)(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize, 3, padding='same')(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize * 4, 1)(x)
    x = layers.BatchNormalization(axis=3)(x)
    res = layers.Conv2D(fsize * 4, 1, strides=sstep)(res)
    res = layers.BatchNormalization(axis=3)(res)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)

    res = x
    x = layers.Conv2D(fsize, 1)(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize, 3, padding='same')(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize * 4, 1)(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    res = x
    x = layers.Conv2D(fsize, 1)(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize, 3, padding='same')(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(fsize * 4, 1)(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)

x = layers.AveragePooling2D(2, padding='same')(x)
x = layers.Flatten()(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dropout(0.45)(x)
outp = layers.Dense(55, activation='softmax')(x)




TRes2
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same', activation='relu')(x)
x = layers.BatchNormalization(axis=3)(x)
for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(fsize * 2, 2, strides=2)(res)
    res = layers.BatchNormalization(axis=3)(res)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)

    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1)(x)
    x = layers.BatchNormalization(axis=3)(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)

x = layers.AveragePooling2D(4, 4)(x)
x = layers.Flatten()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)


TRes3
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same', activation='relu')(x)
x = layers.BatchNormalization(axis=3)(x)

for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(fsize * 2, 2, strides=2)(res)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)

    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1)(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1)(x)
    x = layers.add([x, res])
    x = layers.Activation("relu")(x)
    x = layers.BatchNormalization(axis=3)(x)

x = layers.Conv2D(256, 3, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)





TRes4	Bad Read
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same', activation='relu')(x)

for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(fsize * 2, 2, strides=2)(res)
    x = layers.add([x, res])
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1, activation='relu')(x)
    x = layers.add([x, res])
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize * 2, 1, activation='relu')(x)
    x = layers.add([x, res])

x = layers.Conv2D(256, 3, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)



TRES5	Good Read
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)

for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(2 * fsize, 2, strides=2, activation='relu')(res)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)

x = layers.Conv2D(256, 3, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)



TRes8
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)

for fsize in [32, 64, 128]:
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(3 * fsize, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(3 * fsize, 2, strides=2, activation='relu')(res)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(3 * fsize, 1, activation='relu')(x)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)

x = layers.Conv2D(256, 3, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)





TRes9
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)

for fsize in [32, 64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(3 * fsize, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(3 * fsize, 2, strides=2, activation='relu')(res)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(3 * fsize, 1, activation='relu')(x)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)

x = layers.Conv2D(256, 3, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)


TRes 10
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)

for fsize in [32, 64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(2 * fsize, 2, strides=2, activation='relu')(res)
    res = layers.BatchNormalization(axis=3)(res)
    x = layers.add([x, res])

x = layers.Conv2D(256, 3, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)






TRes11
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)

for fsize in [32, 64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(2 * fsize, 2, strides=2, activation='relu')(res)
    x = layers.add([x, res])
    res = layers.BatchNormalization(axis=3)(res)

    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.add([x, res])
    res = x
    x = layers.Conv2D(fsize, 1, activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)

x = layers.Conv2D(256, 3, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)


opti = keras.optimizers.Adam(learning_rate=0.001)
ccls = keras.Model(inp, outp, name='text_class')
ccls.compile(optimizer=opti, loss='categorical_crossentropy', metrics=['categorical_accuracy'])
log_dir = "tblogs/classification/0/"
tbcall = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)



TRes12
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(64, 5, padding='same')(x)
x = layers.BatchNormalization(axis=3)(x)
x = layers.Activation("relu")(x)

for fsize in [64, 128, 256]:
    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.101)(x)
    res = layers.Conv2D(2 * fsize, 2, strides=2, activation='relu')(res)
    x = layers.add([x, res])
    res = layers.BatchNormalization(axis=3)(res)

    res = x
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(2 * fsize, 1, activation='relu')(x)
    x = layers.add([x, res])
    x = layers.BatchNormalization(axis=3)(x)

x = layers.AveragePooling2D(4, 4)(x)
x = layers.Flatten()(x)
x = layers.Dense(512, activation='relu')(x)
x = layers.Dense(512, activation='relu')(x)
x = layers.Dropout(0.3678)(x)
outp = layers.Dense(55, activation='softmax')(x)


_________________________



_________________________
Detector
_________________________

1st Model 	95.1% Accuracy	3.48M parameters

x = layers.Rescaling(1.0/255)(inlay)
x = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(x)
x = layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.24)(x)
x = layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.24)(x)
x = layers.Flatten()(x)
x = layers.Dense(512, activation='relu')(x)
x = layers.Dropout(0.24)(x)
x = layers.Dense(512, activation='relu')(x)


Improved	 3x1	16s	333	128		92.22% Accuracy		0.208 Loss		564k parameters

x = layers.Rescaling(1.0/255)(inlay)
x = layers.Conv2D(16, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.12)(x)
x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.12)(x)
x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.12)(x)
x = layers.Flatten()(x)
x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dropout(0.32)(x)
x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)

tdetect-1	Score: 0.952 VAccuracy: 0.983 VLoss: 0.0547
inp = keras.Input(shape=(64, 64, 1))
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 5, padding='same', activation=None)(x)
res_last = x

for fsize in [32, 64, 128, 256]:
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.Conv2D(fsize, 3, padding='same', activation='relu')(x)
    x = layers.MaxPooling2D(pool_size=(2, 2))(x)
    x = layers.Dropout(0.1)(x)
    res = layers.Conv2D(fsize, 1, strides=2, padding="same", activation=None)(res_last)
    x = layers.add([x, res])
    res_last = x

x = layers.Flatten()(x)
x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dropout(0.45)(x)
outp = layers.Dense(1, activation='sigmoid')(x)
_________________________
Segmentation
_________________________

1st Attempt

x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(16, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(16, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.08)(x)
x = layers.Flatten()(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dropout(0.32)(x)


Resnet
x = layers.Rescaling(1.0/255)(inp)
x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)
res_last = x
x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.1)(x)
res = layers.Conv2D(128, 1, strides=2, padding="same")(res_last)
x = layers.add([x, res])
res_last = x
x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2, 2))(x)
x = layers.Dropout(0.1)(x)
res = layers.Conv2D(256, 1, strides=2, padding="same")(res_last)
x = layers.add([x, res])
x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Flatten()(x)
x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = layers.Dropout(0.45)(x)



