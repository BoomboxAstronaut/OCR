{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f\"{os.environ['base']}Tools\")\n",
    "\n",
    "import btk\n",
    "import cv2 as cv\n",
    "import dataset_generators as dgen\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "plt.style.use(f\"{os.environ['style']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' trainy = case_fix(trainy, dgen.allchars)\\nvaly = case_fix(valy, dgen.allchars) '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainx, trainy, valx, valy = btk.depickler('trainx-1643703742', 'trainy-1643703742', 'valx-1643703742', 'valy-1643703742', 'ocr')\n",
    "#trainx, trainy, valx, valy = btk.depickler('trainx-1643708634', 'trainy-1643708634', 'valx-1643708634', 'valy-1643708634', 'ocr')\n",
    "\n",
    "\"\"\" trainx, trainy = dgen.gen_chars(630000, dgen.allchars, dgen.trainfonts, True)\n",
    "valx, valy = dgen.gen_chars(225000, dgen.allchars, dgen.evalfonts) \"\"\"\n",
    "\n",
    "\"\"\" trainx, trainy = dgen.gen_chars(315000, dgen.hardc, dgen.trainfonts, True)\n",
    "valx, valy = dgen.gen_chars(110000, dgen.hardc, dgen.evalfonts, False) \"\"\"\n",
    "\n",
    "\"\"\" trainy = case_fix(trainy, dgen.allchars)\n",
    "valy = case_fix(valy, dgen.allchars) \"\"\"\n",
    "\n",
    "#btk.pickle_set(trainx, trainy, valx, valy, 'ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character Classifier with CNN\n",
    "\n",
    "imgent = btk.DataGen(trainx, trainy, 192)\n",
    "imgenv = btk.DataGen(valx, valy, 64)\n",
    "\n",
    "\n",
    "opti = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "log_dir = \"tblogs/ccls-l/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tbcall = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "estop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=24, restore_best_weights=True)\n",
    "\n",
    "\n",
    "inlay = keras.Input(shape=(64, 64, 1))\n",
    "x = layers.Rescaling(1.0/255)(inlay)\n",
    "x = layers.Conv2D(32, 7, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(32, 7, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.08)(x)\n",
    "x = layers.Conv2D(64, 5, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, 5, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.08)(x)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.08)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "x = layers.Dropout(0.32)(x)\n",
    "x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "outlay = layers.Dense(54, activation='softmax')(x)\n",
    "\n",
    "\n",
    "ccls = keras.Model(inlay, outlay, name='text_class')\n",
    "ccls.compile(\n",
    "    optimizer=opti,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "history = ccls.fit(\n",
    "    x = imgent,\n",
    "    validation_data=imgenv,\n",
    "    epochs=200,\n",
    "    steps_per_epoch=16,\n",
    "    validation_steps=16,\n",
    "    callbacks=[estop, tbcall],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist[['categorical_accuracy', 'val_categorical_accuracy']].plot()\n",
    "display(hist['val_categorical_accuracy'].max())\n",
    "display(hist['val_loss'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_fix(yar, superset):\n",
    "    case_dic = {superset.index(x): superset.index(dgen.icase_chars[i]) for i, x in enumerate(dgen.case_chars)}\n",
    "    for i, x in enumerate(yar):\n",
    "        if x.argmax() in case_dic:\n",
    "            tmp = x.argmax()\n",
    "            yar[i][tmp] = 0\n",
    "            yar[i][case_dic.get(tmp)] = 1\n",
    "    return np.delete(yar, sorted(case_dic, reverse=True), 1)\n",
    "\n",
    "ccls = tf.keras.models.load_model('models\\\\ccls-h')\n",
    "#ccls.save('models\\\\ccls-h')\n",
    "#ccls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test classifier on images from segmentation module\n",
    "ccls = tf.keras.models.load_model('models\\\\ccls-h')\n",
    "\n",
    "with open('segset2', 'rb') as pkf:\n",
    "    segset = btk.pickle.load(pkf)\n",
    "\n",
    "csets = []\n",
    "for x in segset:\n",
    "    tmpset = []\n",
    "    for y in x:\n",
    "        image = np.array(Image.new(mode='L', color=15, size=(64, 64)))\n",
    "        if y.size[0] > 32:\n",
    "            pass\n",
    "        else:\n",
    "            im = y.resize((y.size[0] * 2, y.size[1] * 2))\n",
    "            image[:, int(32 - y.size[0]):int(32 + y.size[0])] = im\n",
    "            tmpset.append(image)\n",
    "    csets.append(np.array(tmpset))\n",
    "\n",
    "\n",
    "\"\"\" sharp = csets[0]\n",
    "sharp = [cv.GaussianBlur(x, (3, 3), 5) for x in csets[0]]\n",
    "sharp = [cv.GaussianBlur(x, (3, 3), 5) for x in sharp]\n",
    "sharp = [cv.filter2D(src=x, ddepth=-1, kernel=btk.sharpenk) for x in sharp]\n",
    "sharp = [cv.GaussianBlur(x, (3, 3), 5) for x in sharp]\n",
    "sharp = [cv.filter2D(src=x, ddepth=-1, kernel=btk.sharpenk) for x in sharp]\n",
    "sharp = [cv.GaussianBlur(x, (3, 3), 5) for x in sharp]\n",
    "sharp = [cv.filter2D(src=x, ddepth=-1, kernel=btk.sharpenk) for x in sharp]\n",
    "sharp = [cv.GaussianBlur(x, (3, 3), 5) for x in sharp]\n",
    "sharp = [cv.filter2D(src=x, ddepth=-1, kernel=btk.sharpenk) for x in sharp]\n",
    "\n",
    "sharp = np.array(sharp) \"\"\"\n",
    "\n",
    "ctest = ccls.predict(csets[0])\n",
    "\n",
    "for i, x in enumerate(csets[0]):\n",
    "    display(Image.fromarray(x))\n",
    "    display(dgen.chars1[ctest[i].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test classifier on generated images or test generator\n",
    "tx, ty = dgen.gen_chars(15, dgen.hardc, dgen.trainfonts, True)\n",
    "preds = iocls.predict(tx)\n",
    "\n",
    "for i, x in enumerate(tx):\n",
    "    display(Image.fromarray(x))\n",
    "    display(dgen.hardc[preds[i].argmax()])\n",
    "    for j, y in enumerate(ty[i]):\n",
    "        if y == 1:\n",
    "            display(dgen.hardc[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing generated data vs model\n",
    "\n",
    "tx, ty = dgen.gen_chars(5000, dgen.hardc, dgen.trainfonts, False, dgen.allchars)\n",
    "ty = case_fix(ty, dgen.allchars)\n",
    "preds = ccls.predict(tx)\n",
    "\n",
    "guess = [dgen.chars1[preds[i].argmax()] for i in range(len(tx) - 1)]\n",
    "real = [dgen.chars1[ty[i].argmax()] for i in range(len(ty) - 1)]\n",
    "\n",
    "conf = confusion_matrix(y_true=real, y_pred=guess, labels=dgen.chars1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(24, 24)\n",
    "im = ax.imshow(conf)\n",
    "\n",
    "ax.set_xticks(np.arange(len(dgen.chars1)), labels=list(dgen.chars1))\n",
    "ax.set_yticks(np.arange(len(dgen.chars1)), labels=list(dgen.chars1))\n",
    "for i in range(len(dgen.chars1)):\n",
    "    for j in range(len(dgen.chars1)):\n",
    "        text = ax.text(j, i, conf[i, j], ha='center', va='center', color='w')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "incorrect = []\n",
    "\n",
    "for i, x in enumerate(guess):\n",
    "    if x == real[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect.append((x, real[i]))\n",
    "\n",
    "    \n",
    "display(f'{correct / 10000 * 100}% accuract')\n",
    "display(btk.count(incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(125, 175):\n",
    "    display(Image.fromarray(trainx[i]))\n",
    "    for j, y in enumerate(trainy[i]):\n",
    "        if y == 1:\n",
    "            display(dgen.chars1[j])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba2123b71ace3df70a1445b18c2163a609e4c738d01cc4864186bed5eddac94c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
